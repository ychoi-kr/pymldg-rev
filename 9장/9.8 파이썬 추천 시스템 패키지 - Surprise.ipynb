{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import surprise \n",
    "\n",
    "print(surprise.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise 를 이용한 추천 시스템 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset \n",
    "from surprise import accuracy \n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Y\n",
      "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
      "Done! Dataset ml-100k has been saved to C:\\Users\\yong/.surprise_data/ml-100k\n"
     ]
    }
   ],
   "source": [
    "# 실행하면 다음 오류가 발생합니다.\n",
    "#\"URLError: <urlopen error [WinError 10060] 연결된 구성원으로부터 응답이 없어 연결하지 못했거나, 호스트로부터 응답이 없어 연결이 끊어졌습니다>\"\n",
    "# 데이터셋을 제공하는 grouplens.org 사이트에 https가 아닌 http로 요청하면 응답하지 않는 것이 원인으로 보입니다.\n",
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yong\\anaconda3\\envs\\pymldgrev2\\lib\\site-packages\\surprise\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "# 조치 방법 1-1\n",
    "# 설치된 surprise 패키지의 builtin_datasets.py 파일 경로를 확인\n",
    "print(surprise.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"This module contains built-in datasets that can be automatically\n",
      "downloaded.\"\"\"\n",
      "\n",
      "from __future__ import (absolute_import, division, print_function,\n",
      "                        unicode_literals)\n",
      "\n",
      "import zipfile\n",
      "import os\n",
      "import errno\n",
      "\n",
      "from os.path import join\n",
      "from collections import namedtuple\n",
      "from six.moves.urllib.request import urlretrieve\n",
      "\n",
      "\n",
      "def get_dataset_dir():\n",
      "    \"\"\"Return folder where downloaded datasets and other data are stored.\n",
      "    Default folder is ~/.surprise_data/, but it can also be set by the\n",
      "    environment variable ``SURPRISE_DATA_FOLDER``.\n",
      "    \"\"\"\n",
      "\n",
      "    folder = os.environ.get('SURPRISE_DATA_FOLDER', os.path.expanduser('~') +\n",
      "                            '/.surprise_data/')\n",
      "    try:\n",
      "        os.makedirs(folder)\n",
      "    except OSError as e:\n",
      "        if e.errno != errno.EEXIST:\n",
      "            # reraise exception if folder does not exist and creation failed.\n",
      "            raise\n",
      "\n",
      "    return folder\n",
      "\n",
      "\n",
      "# a builtin dataset has\n",
      "# - an url (where to download it)\n",
      "# - a path (where it is located on the filesystem)\n",
      "# - the parameters of the corresponding reader\n",
      "BuiltinDataset = namedtuple('BuiltinDataset', ['url', 'path', 'reader_params'])\n",
      "\n",
      "BUILTIN_DATASETS = {\n",
      "    'ml-100k':\n",
      "        BuiltinDataset(\n",
      "            url='http://files.grouplens.org/datasets/movielens/ml-100k.zip',\n",
      "            path=join(get_dataset_dir(), 'ml-100k/ml-100k/u.data'),\n",
      "            reader_params=dict(line_format='user item rating timestamp',\n",
      "                               rating_scale=(1, 5),\n",
      "                               sep='\\t')\n",
      "        ),\n",
      "    'ml-1m':\n",
      "        BuiltinDataset(\n",
      "            url='http://files.grouplens.org/datasets/movielens/ml-1m.zip',\n",
      "            path=join(get_dataset_dir(), 'ml-1m/ml-1m/ratings.dat'),\n",
      "            reader_params=dict(line_format='user item rating timestamp',\n",
      "                               rating_scale=(1, 5),\n",
      "                               sep='::')\n",
      "        ),\n",
      "    'jester':\n",
      "        BuiltinDataset(\n",
      "            url='http://eigentaste.berkeley.edu/dataset/archive/jester_dataset_2.zip',\n",
      "            path=join(get_dataset_dir(), 'jester/jester_ratings.dat'),\n",
      "            reader_params=dict(line_format='user item rating',\n",
      "                               rating_scale=(-10, 10))\n",
      "        )\n",
      "}\n",
      "\n",
      "\n",
      "def download_builtin_dataset(name):\n",
      "\n",
      "    dataset = BUILTIN_DATASETS[name]\n",
      "\n",
      "    print('Trying to download dataset from ' + dataset.url + '...')\n",
      "    tmp_file_path = join(get_dataset_dir(), 'tmp.zip')\n",
      "    urlretrieve(dataset.url, tmp_file_path)\n",
      "\n",
      "    with zipfile.ZipFile(tmp_file_path, 'r') as tmp_zip:\n",
      "        tmp_zip.extractall(join(get_dataset_dir(), name))\n",
      "\n",
      "    os.remove(tmp_file_path)\n",
      "    print('Done! Dataset', name, 'has been saved to',\n",
      "          join(get_dataset_dir(), name))\n"
     ]
    }
   ],
   "source": [
    "# 조치 방법 1-2\n",
    "# BUILTIN_DATASETS 딕셔너리의 'ml-100k' 의 url 문자열의 'http'를 'https'로 수정.\n",
    "!type C:\\Users\\yong\\anaconda3\\envs\\pymldgrev2\\lib\\site-packages\\surprise\\builtin_datasets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ml-100k': BuiltinDataset(url='http://files.grouplens.org/datasets/movielens/ml-100k.zip', path='C:\\\\Users\\\\yong/.surprise_data/ml-100k/ml-100k/u.data', reader_params={'line_format': 'user item rating timestamp', 'rating_scale': (1, 5), 'sep': '\\t'}),\n",
       " 'ml-1m': BuiltinDataset(url='http://files.grouplens.org/datasets/movielens/ml-1m.zip', path='C:\\\\Users\\\\yong/.surprise_data/ml-1m/ml-1m/ratings.dat', reader_params={'line_format': 'user item rating timestamp', 'rating_scale': (1, 5), 'sep': '::'}),\n",
       " 'jester': BuiltinDataset(url='http://eigentaste.berkeley.edu/dataset/archive/jester_dataset_2.zip', path='C:\\\\Users\\\\yong/.surprise_data/jester/jester_ratings.dat', reader_params={'line_format': 'user item rating', 'rating_scale': (-10, 10)})}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 조치 방법 2-1\n",
    "# BUILTIN_DATASETS 딕셔너리 확인\n",
    "surprise.builtin_datasets.BUILTIN_DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조치 방법 2-2\n",
    "# BUILTIN_DATASETS 딕셔너리의 'ml-100k'를 교체\n",
    "surprise.builtin_datasets.BUILTIN_DATASETS['ml-100k'] = surprise.builtin_datasets.BuiltinDataset(url='https://files.grouplens.org/datasets/movielens/ml-100k.zip', path='C:\\\\Users\\\\yong/.surprise_data/ml-100k/ml-100k/u.data', reader_params={'line_format': 'user item rating timestamp', 'rating_scale': (1, 5), 'sep': '\\t'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Y\n",
      "Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
      "Done! Dataset ml-100k has been saved to C:\\Users\\yong/.surprise_data/ml-100k\n"
     ]
    }
   ],
   "source": [
    "# 재시도\n",
    "data = Dataset.load_builtin('ml-100k') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x2194fb6dff0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD()\n",
    "algo.fit(trainset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction type : <class 'list'>  size: 25000\n",
      "prediction 결과의 최초 5개 추출\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='120', iid='282', r_ui=4.0, est=3.636089959951193, details={'was_impossible': False}),\n",
       " Prediction(uid='882', iid='291', r_ui=4.0, est=3.9020730610380165, details={'was_impossible': False}),\n",
       " Prediction(uid='535', iid='507', r_ui=5.0, est=3.996625104928444, details={'was_impossible': False}),\n",
       " Prediction(uid='697', iid='244', r_ui=5.0, est=3.7176669164848013, details={'was_impossible': False}),\n",
       " Prediction(uid='751', iid='385', r_ui=4.0, est=3.3794697362295243, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = algo.test( testset )\n",
    "print('prediction type :',type(predictions), ' size:',len(predictions))\n",
    "print('prediction 결과의 최초 5개 추출')\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('120', '282', 3.636089959951193),\n",
       " ('882', '291', 3.9020730610380165),\n",
       " ('535', '507', 3.996625104928444)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (pred.uid, pred.iid, pred.est) for pred in predictions[:3] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = None   est = 4.17   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# 사용자 아이디, 아이템 아이디는 문자열로 입력해야 함. \n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "pred = algo.predict(uid, iid)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9465747505874536"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise 주요 모듈 소개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "# ratings_noh.csv 파일로 unload 시 index 와 header를 모두 제거한 새로운 파일 생성.  \n",
    "ratings.to_csv('./ml-latest-small/ratings_noh.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader\n",
    "\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', rating_scale=(0.5, 5))\n",
    "data=Dataset.load_from_file('./ml-latest-small/ratings_noh.csv',reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8681952927143516"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
    "\n",
    "# 수행시마다 동일한 결과 도출을 위해 random_state 설정 \n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "\n",
    "# 학습 데이터 세트로 학습 후 테스트 데이터 세트로 평점 예측 후 RMSE 평가\n",
    "algo.fit(trainset) \n",
    "predictions = algo.test( testset )\n",
    "accuracy.rmse(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8681952927143516"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader, Dataset\n",
    "\n",
    "ratings = pd.read_csv('./ml-latest-small/ratings.csv') \n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# ratings DataFrame 에서 컬럼은 사용자 아이디, 아이템 아이디, 평점 순서를 지켜야 합니다. \n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
    "\n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "algo.fit(trainset) \n",
    "predictions = algo.test( testset )\n",
    "accuracy.rmse(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 검증과 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.8777  0.8715  0.8722  0.8716  0.8706  0.8727  0.0025  \n",
      "MAE (testset)     0.6734  0.6709  0.6725  0.6695  0.6672  0.6707  0.0022  \n",
      "Fit time          3.15    3.18    3.16    3.12    3.15    3.15    0.02    \n",
      "Test time         0.09    0.09    0.19    0.09    0.09    0.11    0.04    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.87774261, 0.87151004, 0.87222609, 0.87161525, 0.87063444]),\n",
       " 'test_mae': array([0.67339897, 0.67094638, 0.67250519, 0.66948402, 0.66718352]),\n",
       " 'fit_time': (3.1489789485931396,\n",
       "  3.181527853012085,\n",
       "  3.1582796573638916,\n",
       "  3.1223626136779785,\n",
       "  3.1519360542297363),\n",
       " 'test_time': (0.09416532516479492,\n",
       "  0.09424495697021484,\n",
       "  0.1884136199951172,\n",
       "  0.09424066543579102,\n",
       "  0.09425878524780273)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# 판다스 DataFrame에서 Surprise 데이터 세트로 데이터 로딩\n",
    "ratings = pd.read_csv('./ml-latest-small/ratings.csv') # reading data in pandas df\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "algo = SVD(random_state=0)\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8767973513293925\n",
      "{'n_epochs': 20, 'n_factors': 50}\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "# 최적화할 파라미터를 딕셔너리 형태로 지정.\n",
    "param_grid = {'n_epochs': [20, 40, 60], 'n_factors': [50, 100, 200] }\n",
    "\n",
    "# CV를 3개 폴드 세트로 지정, 성능 평가는 rmse, mse로 수행하도록 GridSearchCV 구성\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
    "gs.fit(data)\n",
    "\n",
    "# 최고 RMSE Evaluation 점수와 그때의 하이퍼 파라미터\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise 를 이용한 개인화 영화 추천 시스템 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetAutoFolds' object has no attribute 'global_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mload_from_df(ratings[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovieId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m]], reader)\n\u001b[0;32m      3\u001b[0m algo \u001b[38;5;241m=\u001b[39m SVD(n_factors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pymldgrev2\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx:155\u001b[0m, in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.fit\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pymldgrev2\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx:204\u001b[0m, in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVD.sgd\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DatasetAutoFolds' object has no attribute 'global_mean'"
     ]
    }
   ],
   "source": [
    "# 다음 코드는 train_test_split( )으로 분리되지 않는 데이터 세트에 fit( )을 호출해 오류가 발생합니다.\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "algo.fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.dataset import DatasetAutoFolds\n",
    "\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', rating_scale=(0.5, 5))\n",
    "# DatasetAutoFolds 클래스를 ratings_noh.csv 파일 기반으로 생성. \n",
    "data_folds = DatasetAutoFolds(ratings_file='./ml-latest-small/ratings_noh.csv', reader=reader)\n",
    "\n",
    "#전체 데이터를 학습데이터로 생성함. \n",
    "trainset = data_folds.build_full_trainset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x219265d41f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD(n_epochs=20, n_factors=50, random_state=0)\n",
    "algo.fit(trainset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용자 아이디 9는 영화 아이디 42의 평점 없음\n",
      "    movieId                   title              genres\n",
      "38       42  Dead Presidents (1995)  Action|Crime|Drama\n"
     ]
    }
   ],
   "source": [
    "# 영화에 대한 상세 속성 정보 DataFrame로딩\n",
    "movies = pd.read_csv('./ml-latest-small/movies.csv')\n",
    "\n",
    "# userId=9 의 movieId 데이터 추출하여 movieId=42 데이터가 있는지 확인. \n",
    "movieIds = ratings[ratings['userId']==9]['movieId']\n",
    "if movieIds[movieIds==42].count() == 0:\n",
    "    print('사용자 아이디 9는 영화 아이디 42의 평점 없음')\n",
    "\n",
    "print(movies[movies['movieId']==42])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 9          item: 42         r_ui = None   est = 3.13   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "uid = str(9)\n",
    "iid = str(42)\n",
    "\n",
    "pred = algo.predict(uid, iid, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평점 매긴 영화수: 46 추천대상 영화수: 9696 전체 영화수: 9742\n"
     ]
    }
   ],
   "source": [
    "def get_unseen_surprise(ratings, movies, userId):\n",
    "    #입력값으로 들어온 userId에 해당하는 사용자가 평점을 매긴 모든 영화를 리스트로 생성\n",
    "    seen_movies = ratings[ratings['userId']== userId]['movieId'].tolist()\n",
    "    \n",
    "    # 모든 영화들의 movieId를 리스트로 생성. \n",
    "    total_movies = movies['movieId'].tolist()\n",
    "    \n",
    "    # 모든 영화들의 movieId중 이미 평점을 매긴 영화의 movieId를 제외하여 리스트로 생성\n",
    "    unseen_movies= [movie for movie in total_movies if movie not in seen_movies]\n",
    "    print('평점 매긴 영화수:',len(seen_movies), '추천대상 영화수:',len(unseen_movies), \\\n",
    "          '전체 영화수:',len(total_movies))\n",
    "    \n",
    "    return unseen_movies\n",
    "\n",
    "unseen_movies = get_unseen_surprise(ratings, movies, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평점 매긴 영화수: 46 추천대상 영화수: 9696 전체 영화수: 9742\n",
      "##### Top-10 추천 영화 리스트 #####\n",
      "Usual Suspects, The (1995) : 4.306302135700814\n",
      "Star Wars: Episode IV - A New Hope (1977) : 4.281663842987387\n",
      "Pulp Fiction (1994) : 4.278152632122759\n",
      "Silence of the Lambs, The (1991) : 4.226073566460876\n",
      "Godfather, The (1972) : 4.1918097904381995\n",
      "Streetcar Named Desire, A (1951) : 4.154746591122658\n",
      "Star Wars: Episode V - The Empire Strikes Back (1980) : 4.122016128534504\n",
      "Star Wars: Episode VI - Return of the Jedi (1983) : 4.108009609093436\n",
      "Goodfellas (1990) : 4.083464936588478\n",
      "Glory (1989) : 4.07887165526957\n"
     ]
    }
   ],
   "source": [
    "def recomm_movie_by_surprise(algo, userId, unseen_movies, top_n=10):\n",
    "    # 알고리즘 객체의 predict() 메서드를 평점이 없는 영화에 반복 수행한 후 결과를 list 객체로 저장\n",
    "    predictions = [algo.predict(str(userId), str(movieId)) for movieId in unseen_movies]\n",
    "    \n",
    "    # predictions list 객체는 surprise의 Predictions 객체를 원소로 가지고 있음.\n",
    "    # [Prediction(uid='9', iid='1', est=3.69), Prediction(uid='9', iid='2', est=2.98),,,,]\n",
    "    # 이를 est 값으로 정렬하기 위해서 아래의 sortkey_est 함수를 정의함.\n",
    "    # sortkey_est 함수는 list 객체의 sort() 함수의 키 값으로 사용되어 정렬 수행.\n",
    "    def sortkey_est(pred):\n",
    "        return pred.est\n",
    "    \n",
    "    # sortkey_est( ) 반환값의 내림 차순으로 정렬 수행하고 top_n개의 최상위 값 추출.\n",
    "    predictions.sort(key=sortkey_est, reverse=True)\n",
    "    top_predictions= predictions[:top_n]\n",
    "    \n",
    "    # top_n으로 추출된 영화의 정보 추출. 영화 아이디, 추천 예상 평점, 제목 추출\n",
    "    top_movie_ids = [ int(pred.iid) for pred in top_predictions]\n",
    "    top_movie_rating = [ pred.est for pred in top_predictions]\n",
    "    top_movie_titles = movies[movies.movieId.isin(top_movie_ids)]['title']\n",
    "    top_movie_preds = [ (id, title, rating) for id, title, rating in zip(top_movie_ids, top_movie_titles, top_movie_rating)]\n",
    "    \n",
    "    return top_movie_preds\n",
    "\n",
    "unseen_movies = get_unseen_surprise(ratings, movies, 9)\n",
    "top_movie_preds = recomm_movie_by_surprise(algo, 9, unseen_movies, top_n=10)\n",
    "print('##### Top-10 추천 영화 리스트 #####')\n",
    "\n",
    "for top_movie in top_movie_preds:\n",
    "    print(top_movie[1], \":\", top_movie[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
